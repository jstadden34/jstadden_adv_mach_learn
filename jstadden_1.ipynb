{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "jstadden_1",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jstadden34/jstadden_adv_mach_learn/blob/master/jstadden_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wgw7MbgbU59t"
      },
      "source": [
        "Original Example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZR8LtEfHa7L"
      },
      "source": [
        "import keras\r\n",
        "keras.__version__\r\n",
        "\r\n",
        "from keras.datasets import imdb\r\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\r\n",
        "\r\n",
        "train_data[0]\r\n",
        "\r\n",
        "train_labels[0]\r\n",
        "\r\n",
        "max([max(sequence) for sequence in train_data])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def vectorize_sequences(sequences, dimension=10000):\r\n",
        "    # Create an all-zero matrix of shape (len(sequences), dimension)\r\n",
        "    results = np.zeros((len(sequences), dimension))\r\n",
        "    for i, sequence in enumerate(sequences):\r\n",
        "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\r\n",
        "    return results\r\n",
        "\r\n",
        "\r\n",
        "# Our vectorized training data\r\n",
        "x_train = vectorize_sequences(train_data)\r\n",
        "# Our vectorized test data\r\n",
        "x_test = vectorize_sequences(test_data)\r\n",
        "\r\n",
        "x_train[0]\r\n",
        "\r\n",
        "\r\n",
        "# Our vectorized labels\r\n",
        "y_train = np.asarray(train_labels).astype('float32')\r\n",
        "y_test = np.asarray(test_labels).astype('float32')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "from keras import optimizers\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "from keras import losses\r\n",
        "from keras import metrics\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss=losses.binary_crossentropy,\r\n",
        "              metrics=[metrics.binary_accuracy])\r\n",
        "\r\n",
        "\r\n",
        "x_val = x_train[:10000]\r\n",
        "partial_x_train = x_train[10000:]\r\n",
        "\r\n",
        "y_val = y_train[:10000]\r\n",
        "partial_y_train = y_train[10000:]\r\n",
        "\r\n",
        "\r\n",
        "history = model.fit(partial_x_train,\r\n",
        "                    partial_y_train,\r\n",
        "                    epochs=20,\r\n",
        "                    batch_size=512,\r\n",
        "                    validation_data=(x_val, y_val))\r\n",
        "\r\n",
        "history_dict = history.history\r\n",
        "history_dict.keys()\r\n",
        "\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\r\n",
        "results = model.evaluate(x_test, y_test)\r\n",
        "\r\n",
        "\r\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tnnOjDRUyE-"
      },
      "source": [
        "1 a) Change: 1 hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prcRJdbFK8Ow"
      },
      "source": [
        "\r\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\r\n",
        "\r\n",
        "train_data[0]\r\n",
        "\r\n",
        "train_labels[0]\r\n",
        "\r\n",
        "max([max(sequence) for sequence in train_data])\r\n",
        "\r\n",
        "\r\n",
        "def vectorize_sequences(sequences, dimension=10000):\r\n",
        "    # Create an all-zero matrix of shape (len(sequences), dimension)\r\n",
        "    results = np.zeros((len(sequences), dimension))\r\n",
        "    for i, sequence in enumerate(sequences):\r\n",
        "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\r\n",
        "    return results\r\n",
        "\r\n",
        "# Our vectorized training data\r\n",
        "x_train = vectorize_sequences(train_data)\r\n",
        "# Our vectorized test data\r\n",
        "x_test = vectorize_sequences(test_data)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Our vectorized labels\r\n",
        "y_train = np.asarray(train_labels).astype('float32')\r\n",
        "y_test = np.asarray(test_labels).astype('float32')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss=losses.binary_crossentropy,\r\n",
        "              metrics=[metrics.binary_accuracy])\r\n",
        "\r\n",
        "\r\n",
        "x_val = x_train[:10000]\r\n",
        "partial_x_train = x_train[10000:]\r\n",
        "\r\n",
        "y_val = y_train[:10000]\r\n",
        "partial_y_train = y_train[10000:]\r\n",
        "\r\n",
        "\r\n",
        "history = model.fit(partial_x_train,\r\n",
        "                    partial_y_train,\r\n",
        "                    epochs=20,\r\n",
        "                    batch_size=512,\r\n",
        "                    validation_data=(x_val, y_val))\r\n",
        "\r\n",
        "history_dict = history.history\r\n",
        "history_dict.keys()\r\n",
        "\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\r\n",
        "results = model.evaluate(x_test, y_test)\r\n",
        "\r\n",
        "\r\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmkTjUD_Uuhm"
      },
      "source": [
        "Discuss:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nWPuoUBUtQH"
      },
      "source": [
        "1 b) Change: 3 hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di9tHekaTwa8"
      },
      "source": [
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss=losses.binary_crossentropy,\r\n",
        "              metrics=[metrics.binary_accuracy])\r\n",
        "\r\n",
        "\r\n",
        "x_val = x_train[:10000]\r\n",
        "partial_x_train = x_train[10000:]\r\n",
        "\r\n",
        "y_val = y_train[:10000]\r\n",
        "partial_y_train = y_train[10000:]\r\n",
        "\r\n",
        "\r\n",
        "history = model.fit(partial_x_train,\r\n",
        "                    partial_y_train,\r\n",
        "                    epochs=20,\r\n",
        "                    batch_size=512,\r\n",
        "                    validation_data=(x_val, y_val))\r\n",
        "\r\n",
        "history_dict = history.history\r\n",
        "history_dict.keys()\r\n",
        "\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\r\n",
        "results = model.evaluate(x_test, y_test)\r\n",
        "\r\n",
        "\r\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1GYq-nCUrJv"
      },
      "source": [
        "Discuss:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOYDTILsUptR"
      },
      "source": [
        "2 a) Change: 32 hidden units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H0RBCZgUVZN"
      },
      "source": [
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(32, activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss=losses.binary_crossentropy,\r\n",
        "              metrics=[metrics.binary_accuracy])\r\n",
        "\r\n",
        "\r\n",
        "x_val = x_train[:10000]\r\n",
        "partial_x_train = x_train[10000:]\r\n",
        "\r\n",
        "y_val = y_train[:10000]\r\n",
        "partial_y_train = y_train[10000:]\r\n",
        "\r\n",
        "\r\n",
        "history = model.fit(partial_x_train,\r\n",
        "                    partial_y_train,\r\n",
        "                    epochs=20,\r\n",
        "                    batch_size=512,\r\n",
        "                    validation_data=(x_val, y_val))\r\n",
        "\r\n",
        "history_dict = history.history\r\n",
        "history_dict.keys()\r\n",
        "\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(32, activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\r\n",
        "results = model.evaluate(x_test, y_test)\r\n",
        "\r\n",
        "\r\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ltO-cVuUnlk"
      },
      "source": [
        "Discuss:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKcNHFuVUmVe"
      },
      "source": [
        "2 b) Change: 8 hidden units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VTdk3VYUWf0"
      },
      "source": [
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(8, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(8, activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss=losses.binary_crossentropy,\r\n",
        "              metrics=[metrics.binary_accuracy])\r\n",
        "\r\n",
        "\r\n",
        "x_val = x_train[:10000]\r\n",
        "partial_x_train = x_train[10000:]\r\n",
        "\r\n",
        "y_val = y_train[:10000]\r\n",
        "partial_y_train = y_train[10000:]\r\n",
        "\r\n",
        "\r\n",
        "history = model.fit(partial_x_train,\r\n",
        "                    partial_y_train,\r\n",
        "                    epochs=20,\r\n",
        "                    batch_size=512,\r\n",
        "                    validation_data=(x_val, y_val))\r\n",
        "\r\n",
        "history_dict = history.history\r\n",
        "history_dict.keys()\r\n",
        "\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(8, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(8, activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\r\n",
        "results = model.evaluate(x_test, y_test)\r\n",
        "\r\n",
        "\r\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC9oZzhqUj-I"
      },
      "source": [
        "Discuss:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoDPYhXdUZ0T"
      },
      "source": [
        "3 Change: mse loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8FV8wOSUX0U"
      },
      "source": [
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='mse',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss='mse',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss=losses.mse,\r\n",
        "              metrics=[metrics.mse])\r\n",
        "\r\n",
        "\r\n",
        "x_val = x_train[:10000]\r\n",
        "partial_x_train = x_train[10000:]\r\n",
        "\r\n",
        "y_val = y_train[:10000]\r\n",
        "partial_y_train = y_train[10000:]\r\n",
        "\r\n",
        "\r\n",
        "history = model.fit(partial_x_train,\r\n",
        "                    partial_y_train,\r\n",
        "                    epochs=20,\r\n",
        "                    batch_size=512,\r\n",
        "                    validation_data=(x_val, y_val))\r\n",
        "\r\n",
        "history_dict = history.history\r\n",
        "history_dict.keys()\r\n",
        "\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='mse',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\r\n",
        "results = model.evaluate(x_test, y_test)\r\n",
        "\r\n",
        "\r\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tbgmetTUbS0"
      },
      "source": [
        "Discuss:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW5lsjttVrlX"
      },
      "source": [
        "4 Change: tanh activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kpqL106VzN7"
      },
      "source": [
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(16, activation='tanh'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss=losses.binary_crossentropy,\r\n",
        "              metrics=[metrics.binary_accuracy])\r\n",
        "\r\n",
        "\r\n",
        "x_val = x_train[:10000]\r\n",
        "partial_x_train = x_train[10000:]\r\n",
        "\r\n",
        "y_val = y_train[:10000]\r\n",
        "partial_y_train = y_train[10000:]\r\n",
        "\r\n",
        "\r\n",
        "history = model.fit(partial_x_train,\r\n",
        "                    partial_y_train,\r\n",
        "                    epochs=20,\r\n",
        "                    batch_size=512,\r\n",
        "                    validation_data=(x_val, y_val))\r\n",
        "\r\n",
        "history_dict = history.history\r\n",
        "history_dict.keys()\r\n",
        "\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(16, activation='tanh'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\r\n",
        "results = model.evaluate(x_test, y_test)\r\n",
        "\r\n",
        "\r\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNPK5UqLV0la"
      },
      "source": [
        "Discussion:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MODrm1dKpIhb"
      },
      "source": [
        "5 a) Change: Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG8WfeNJpTGY"
      },
      "source": [
        "from keras import regularizers\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss=losses.binary_crossentropy,\r\n",
        "              metrics=[metrics.binary_accuracy])\r\n",
        "\r\n",
        "\r\n",
        "x_val = x_train[:10000]\r\n",
        "partial_x_train = x_train[10000:]\r\n",
        "\r\n",
        "y_val = y_train[:10000]\r\n",
        "partial_y_train = y_train[10000:]\r\n",
        "\r\n",
        "\r\n",
        "history = model.fit(partial_x_train,\r\n",
        "                    partial_y_train,\r\n",
        "                    epochs=20,\r\n",
        "                    batch_size=512,\r\n",
        "                    validation_data=(x_val, y_val))\r\n",
        "\r\n",
        "history_dict = history.history\r\n",
        "history_dict.keys()\r\n",
        "\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\r\n",
        "results = model.evaluate(x_test, y_test)\r\n",
        "\r\n",
        "\r\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVd986VgpTrd"
      },
      "source": [
        "Discussion:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOY3RoXzV3Mn"
      },
      "source": [
        "5 b) Change: Adding Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpDTuQ3ZV6Xz"
      },
      "source": [
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\r\n",
        "              loss=losses.binary_crossentropy,\r\n",
        "              metrics=[metrics.binary_accuracy])\r\n",
        "\r\n",
        "\r\n",
        "x_val = x_train[:10000]\r\n",
        "partial_x_train = x_train[10000:]\r\n",
        "\r\n",
        "y_val = y_train[:10000]\r\n",
        "partial_y_train = y_train[10000:]\r\n",
        "\r\n",
        "\r\n",
        "history = model.fit(partial_x_train,\r\n",
        "                    partial_y_train,\r\n",
        "                    epochs=20,\r\n",
        "                    batch_size=512,\r\n",
        "                    validation_data=(x_val, y_val))\r\n",
        "\r\n",
        "history_dict = history.history\r\n",
        "history_dict.keys()\r\n",
        "\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(16, activation='relu'))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='binary_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\r\n",
        "results = model.evaluate(x_test, y_test)\r\n",
        "\r\n",
        "\r\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6eAXmV8V65I"
      },
      "source": [
        "Discussion:"
      ]
    }
  ]
}